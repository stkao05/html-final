{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, TargetEncoder  # type: ignore\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM\n",
    "\n",
    "#### Done and submitted: \n",
    "1. Every July is held out for test\n",
    "2. dropped 'date' column\n",
    "3. target encoding for categorical features\n",
    "4. label encoding for 'is_night_game' since it is binary\n",
    "5. boosting models works well\n",
    "6. choosed LGBM because it is faster\n",
    "\n",
    "#### Tried but failed:\n",
    "1. SVC seems to fail (best score around 0.52)\n",
    "2. ensembles of RF, SVC, CAT, LGBM together does not help ?\n",
    "3. train with emphasis on later months(by simply duplicated them) does not help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = \"data/task1/train_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data.columns = data.columns.str.strip()\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "\n",
    "TARGET = 'home_team_win'\n",
    "\n",
    "train_data = data[data['date'].dt.month != 7]  \n",
    "hold_out = data[data['date'].dt.month == 7]  \n",
    "\n",
    "X_hold_out = hold_out.drop(columns=[TARGET])\n",
    "y_hold_out = hold_out[TARGET]\n",
    "\n",
    "X_train = train_data.drop(columns=[TARGET])\n",
    "y_train = train_data[TARGET]\n",
    "\n",
    "# transformation function\n",
    "def transform(X_tr, y_tr, X_vl, remove_date=True, fill_na=True):\n",
    "    X_train, y_train, X_val = X_tr.copy(), y_tr.copy(), X_vl.copy()\n",
    "\n",
    "    X_train.drop(columns=['home_team_season', 'away_team_season'], inplace=True)\n",
    "    X_val.drop(columns=['home_team_season', 'away_team_season'], inplace=True)\n",
    "\n",
    "    if remove_date:\n",
    "        if 'date' in X_train.columns:\n",
    "            X_train.drop(columns=['date'], inplace=True)\n",
    "        if 'date' in X_val.columns:\n",
    "            X_val.drop(columns=['date'], inplace=True)\n",
    "\n",
    "    # get categorical and numerical columns\n",
    "    cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    cat_cols.remove('is_night_game')\n",
    "    num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    for i in ['id', 'season']: num_cols.remove(i)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    X_train['is_night_game'] = label_encoder.fit_transform(X_train['is_night_game'])\n",
    "    X_val['is_night_game'] = label_encoder.transform(X_val['is_night_game'])\n",
    "    \n",
    "    encoder = TargetEncoder(random_state=42)\n",
    "    X_train[cat_cols] = encoder.fit_transform(X_train[cat_cols], y_train)\n",
    "    X_val[cat_cols] = encoder.transform(X_val[cat_cols])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_val[num_cols] = scaler.transform(X_val[num_cols])\n",
    "\n",
    "    if fill_na:\n",
    "        X_train.fillna(X_train.median(), inplace=True)\n",
    "        X_val.fillna(X_val.median(), inplace=True)\n",
    "\n",
    "    return X_train, y_train, X_val\n",
    "\n",
    "\"\"\"cross_validation performs cross validation after feature transformation and returns the average accuracy\n",
    "make_iter gives all combinations of hyperparameters\"\"\"\n",
    "\n",
    "\n",
    "def cross_validation(model, params, X, y, num_folds=5):\n",
    "    kf_scores = []\n",
    "    for train, val in KFold(n_splits=num_folds, shuffle=True).split(X):\n",
    "        X_train, y_train = X.iloc[train], y.iloc[train]\n",
    "        X_val, y_val = X.iloc[val], y.iloc[val]\n",
    "\n",
    "        X_train, y_train, X_val = transform(X_train, y_train, X_val, remove_date=True, fill_na=True)\n",
    "\n",
    "        model_ = model(**params)\n",
    "        model_.fit(X_train, y_train)\n",
    "        preds = model_.predict(X_val)\n",
    "        kf_scores.append(np.mean(preds == y_val))\n",
    "    return np.mean(kf_scores)\n",
    "\n",
    "make_iter = lambda p: [dict(zip(p.keys(), combination)) for combination in product(*p.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.037, 'num_leaves': 15, 'verbose': -1}: 0.5474330698497948\n",
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.037, 'num_leaves': 17, 'verbose': -1}: 0.5507517277954088\n",
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.037, 'num_leaves': 20, 'verbose': -1}: 0.5583313691323001\n",
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.04, 'num_leaves': 15, 'verbose': -1}: 0.547672351625657\n",
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.04, 'num_leaves': 17, 'verbose': -1}: 0.5528851307175787\n",
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.04, 'num_leaves': 20, 'verbose': -1}: 0.5486202189242352\n",
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.043, 'num_leaves': 15, 'verbose': -1}: 0.5525272252293205\n",
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.043, 'num_leaves': 17, 'verbose': -1}: 0.5498052634975685\n",
      "{'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.043, 'num_leaves': 20, 'verbose': -1}: 0.5578561727823469\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.037, 'num_leaves': 15, 'verbose': -1}: 0.5500419497220655\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.037, 'num_leaves': 17, 'verbose': -1}: 0.5537105862017684\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.037, 'num_leaves': 20, 'verbose': -1}: 0.550870982858137\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.04, 'num_leaves': 15, 'verbose': -1}: 0.5530026320293844\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.04, 'num_leaves': 17, 'verbose': -1}: 0.5490918376223066\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.04, 'num_leaves': 20, 'verbose': -1}: 0.5496853069344715\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.043, 'num_leaves': 15, 'verbose': -1}: 0.5505142699205059\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.043, 'num_leaves': 17, 'verbose': -1}: 0.5442375953689752\n",
      "{'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.043, 'num_leaves': 20, 'verbose': -1}: 0.5516993846438764\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.037, 'num_leaves': 15, 'verbose': -1}: 0.5485013146116915\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.037, 'num_leaves': 17, 'verbose': -1}: 0.547554990613925\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.037, 'num_leaves': 20, 'verbose': -1}: 0.5547792518638864\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.04, 'num_leaves': 15, 'verbose': -1}: 0.5538299815645702\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.04, 'num_leaves': 17, 'verbose': -1}: 0.5457783707794231\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.04, 'num_leaves': 20, 'verbose': -1}: 0.5456565201653296\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.043, 'num_leaves': 15, 'verbose': -1}: 0.547552184612449\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.043, 'num_leaves': 17, 'verbose': -1}: 0.5538294905143121\n",
      "{'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.043, 'num_leaves': 20, 'verbose': -1}: 0.5469592063505425\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.037, 'num_leaves': 15, 'verbose': -1}: 0.554780935464772\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.037, 'num_leaves': 17, 'verbose': -1}: 0.550399083559918\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.037, 'num_leaves': 20, 'verbose': -1}: 0.5525263834288777\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.04, 'num_leaves': 15, 'verbose': -1}: 0.5515792176306684\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.04, 'num_leaves': 17, 'verbose': -1}: 0.554899629327205\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.04, 'num_leaves': 20, 'verbose': -1}: 0.5480280123127346\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.043, 'num_leaves': 15, 'verbose': -1}: 0.5514627685694162\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.043, 'num_leaves': 17, 'verbose': -1}: 0.5505131475199156\n",
      "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.043, 'num_leaves': 20, 'verbose': -1}: 0.5522914509553032\n",
      "{'n_estimators': 75, 'max_depth': 9, 'learning_rate': 0.037, 'num_leaves': 15, 'verbose': -1}: 0.5537110772520266\n",
      "{'n_estimators': 75, 'max_depth': 9, 'learning_rate': 0.037, 'num_leaves': 17, 'verbose': -1}: 0.5519356499681519\n",
      "{'n_estimators': 75, 'max_depth': 9, 'learning_rate': 0.037, 'num_leaves': 20, 'verbose': -1}: 0.5564363360355127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m X_train_t, y_train, X_val_t \u001b[38;5;241m=\u001b[39m transform(X_train, y_train, X_val, remove_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fill_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)\n\u001b[0;32m---> 24\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_t)\n\u001b[1;32m     26\u001b[0m kf_scores\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(preds \u001b[38;5;241m==\u001b[39m y_val))\n",
      "File \u001b[0;32m~/miniconda3/envs/html-final/lib/python3.10/site-packages/lightgbm/sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1284\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/html-final/lib/python3.10/site-packages/lightgbm/sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/miniconda3/envs/html-final/lib/python3.10/site-packages/lightgbm/engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    296\u001b[0m     cb(\n\u001b[1;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/html-final/lib/python3.10/site-packages/lightgbm/basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4135\u001b[0m _safe_call(\n\u001b[0;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4140\u001b[0m )\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params_lgbm = {\n",
    "    'n_estimators': [70, 75, 80],\n",
    "    'max_depth': [8, 9, 10],\n",
    "    'learning_rate': [0.037, 0.04, 0.043],\n",
    "    'num_leaves': [15, 17, 20],\n",
    "    'verbose': [-1]\n",
    "}\n",
    "\n",
    "num_folds = 5\n",
    "result = []\n",
    "\n",
    "for param in make_iter(params_lgbm):\n",
    "    kf_scores = []\n",
    "    for train, val in KFold(n_splits=num_folds, shuffle=True).split(train_data):\n",
    "        sub_train_data = train_data.iloc[train]  \n",
    "        val_data = train_data.iloc[val]\n",
    "\n",
    "        X_train, y_train = sub_train_data.drop(columns=[TARGET]), sub_train_data[TARGET]\n",
    "        X_val, y_val = val_data.drop(columns=[TARGET]), val_data[TARGET]\n",
    "\n",
    "        X_train_t, y_train, X_val_t = transform(X_train, y_train, X_val, remove_date=True, fill_na=True)\n",
    "\n",
    "        model = LGBMClassifier(**param)\n",
    "        score = model.fit(X_train_t, y_train)\n",
    "        preds = model.predict(X_val_t)\n",
    "        kf_scores.append(np.mean(preds == y_val))\n",
    "\n",
    "    print(f'{param}:', np.mean(kf_scores))\n",
    "    result.append((np.mean(kf_scores), param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort(key=lambda x: x[0], reverse=True)\n",
    "for i in range(15):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best params:\n",
    "\n",
    "{'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.04, 'num_leaves': 15, 'verbose': -1}\n",
    "\n",
    "**Result**\n",
    "\n",
    "Validation accuracy 0.5586 \\\n",
    "Test accuracy 0.5671\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.5585682658069079\n",
      "Test accuracy 0.5670731707317073\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best param\n",
    "val_score_params = [\n",
    "    (0.5585682658069079, {'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.037, 'num_leaves': 17, 'verbose': -1}),\n",
    "    ]\n",
    "\n",
    "for val_score, params in val_score_params:\n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    X_train, y_train = train_data.drop(columns=[TARGET]), train_data[TARGET]\n",
    "    X_train_t, y_train_t, X_hold_out_t = transform(X_train, y_train, X_hold_out, remove_date=True, fill_na=True)\n",
    "    lgbm.fit(X_train_t, y_train_t)\n",
    "    preds = lgbm.predict(X_hold_out_t)\n",
    "    print(f'Validation accuracy', val_score)\n",
    "    print(f'Test accuracy', np.mean(preds == y_hold_out))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try First Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test_file_path = \"data/task1/same_season_test_data.csv\"\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "test_data.columns = test_data.columns.str.strip()\n",
    "\n",
    "X_test = test_data\n",
    "\n",
    "X_train_final = data.drop(columns=[TARGET])\n",
    "y_train_final = data[TARGET]\n",
    "\n",
    "X_train_final_t, y_train_final_t, X_test_t = transform(X_train_final, y_train_final, X_test, remove_date=True, fill_na=True)\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=75, max_depth=8, learning_rate=0.037, num_leaves=17, verbose=-1)\n",
    "lgbm.fit(X_train_final_t, y_train_final_t)\n",
    "preds = lgbm.predict(X_test_t)\n",
    "sub_df = pd.DataFrame({'id': test_data['id'], 'home_team_win': preds})\n",
    "# sub_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "html-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
